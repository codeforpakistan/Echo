{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import featureExtraction\n",
    "import numpy as np\n",
    "import librosa\n",
    "import MFCC\n",
    "import cPickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "featureExtraction.write_to_csv(\"/home/omer/Downloads/humans/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print MFCC.extract_mfcc(\"/home/omer/Desktop/UrbanSound8K/UrbanSound8K/audio/fold1/7061-6-0-0.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "array=np.loadtxt(open(\"/home/omer/Desktop/Echo/Machine_Learning/Data_Gunshot.csv\", \"r\"), delimiter=\",\", skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "np.random.shuffle(array)\n",
    "print array.shape\n",
    "X_train=array[:,1:]\n",
    "\n",
    "    \n",
    "y_train=array[:,0]\n",
    "X_test=array[700:,1:]\n",
    "y_test=array[700:,0]\n",
    "#print y_test\n",
    "print X_test.shape,y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"started\"\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import svm\n",
    "\n",
    "\n",
    "parameters = {'kernel':['rbf'], 'C':[ 10,40,60],'gamma':[0.001,0.007,0.0002,0.0003,0.0009]}\n",
    "svr = svm.SVC()\n",
    "\n",
    "clf =GridSearchCV(svr, parameters)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print clf.best_estimator_\n",
    "\n",
    "print \"trained\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Accuracy on test set is : \",round(clf.score(X_test,y_test),2)*100 ,\"%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# save the classifier\n",
    "with open('my_dumped_classifierrr.pkl', 'wb') as fid:\n",
    "    cPickle.dump(clf, fid)    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn_porter import Porter\n",
    "porter = Porter(clf, language='java')\n",
    "output = porter.export()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "with open('/home/omer/Downloads/humans/my_dumped_classifierrr.pkl', 'rb') as fid:\n",
    "    clf = cPickle.load(fid)\n",
    "\"\"\"y,sr=librosa.load(\"/home/omer/Downloads/videoplayback.wav\")\n",
    "librosa.display.waveplot(y,sr)\n",
    "mfcc=librosa.feature.mfcc(y=y,sr=sr,n_mfcc=60).T\n",
    "mfcc=mfcc\n",
    "i=0\n",
    "j=0\n",
    "print mfcc.shape\n",
    "#print clf.predict(np.mean(mfcc,0).reshape(1,60))\n",
    "while (i<=mfcc.shape[0]):\n",
    "    if(i<=4*42):\n",
    "        j=0\n",
    "        i+=42\n",
    "        continue\n",
    "     \n",
    "    current=np.mean(mfcc[j:i,:],0 ).reshape(1,-1)\n",
    "    print j,\"   \",i \n",
    "    \n",
    "    found=False\n",
    "     \n",
    "    #print clf.predict(current)\n",
    "    if 1== clf.predict(current):\n",
    "        found=True\n",
    "    \n",
    "    i+=42\n",
    "    \n",
    "    j+=42\n",
    "\n",
    "    if(found):\n",
    "        print \"Benazir_Assasinaiton.wav :         GUNSHOT Detected\"\n",
    "     \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "from pydub.utils import make_chunks\n",
    "import os,librosa\n",
    "os.chdir(\"/home/omer/Desktop/\")\n",
    "myaudio = AudioSegment.from_file(\"Echo/Machine_Learning/Benazir Bhutto Assassination Video (Very High Quality).wav\" , \"wav\") \n",
    "chunk_length_ms = 5000 # pydub calculates in millisec\n",
    "chunks = make_chunks(myaudio, chunk_length_ms) #Make chunks of one sec\n",
    "print chunks\n",
    "#Export all of the individual chunks as wav files\n",
    " \n",
    "for i, chunk in enumerate(chunks):\n",
    "    \n",
    "    chunk_name = \"chunk\"+str(i)+\".wav\"\n",
    "    print \"exporting\", chunk_name\n",
    "    chunk.export(chunk_name, format=\"wav\")\n",
    "    y,sr=librosa.load(chunk_name)\n",
    "    \n",
    "    mfcc=librosa.feature.mfcc(y=y,sr=sr,n_mfcc=60).T\n",
    "    print clf.predict(np.mean(mfcc,0).reshape(1,-1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2 , numpy as np,time\n",
    " \n",
    "test_cap=cv2.VideoCapture(\"/home/omer/Videos/fef.avi\")\n",
    "frames=0\n",
    "flag,frame=test_cap.read()\n",
    "while flag!=0:\n",
    "        flag,frame=test_cap.read()\n",
    "        frames+=1\n",
    "fps=frames/32\n",
    "\n",
    "capture=cv2.VideoCapture(\"/home/omer/Videos/fef.avi\")\n",
    "while True:\n",
    "    print \"hi\"\n",
    "    flag,frame=capture.read()\n",
    "    x=200\n",
    "    y=200\n",
    "    col=(255,0,0)\n",
    "    cv2.putText(frame,\"HEllo How The ellk skjfslfn\",(x,y),cv2.FONT_HERSHEY_COMPLEX,1.0,col)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2,os\n",
    "cap = cv2.VideoCapture(\"/home/omer/Downloads/Benazir Bhutto Assassination Video (Very High Quality).mp4\")\n",
    "os.chdir(\"/home/omer/Desktop/\")\n",
    "# Define the codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('output.avi',fourcc, 20.0, (640,480))\n",
    "i=0\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret==True:\n",
    "         \n",
    "        # write the flipped frame\n",
    "        if(i>=65 and i<=95):\n",
    "            cv2.putText(frame, \"GUNSHOT DETECTED\", (120,100), cv2.FONT_HERSHEY_PLAIN, 3, (0,0,255), thickness=7)\n",
    "        out.write(frame)\n",
    "        i+=1\n",
    "        cv2.imshow('frame',frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "# Release everything if job is finished\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import sys\n",
    "\n",
    "cap = cv2.VideoCapture(0) \n",
    "cap.set(3,643)\n",
    "cap.set(4,484)\n",
    "cap.set(15, 0.1)\n",
    "flag, frame = cap.read()\n",
    "width = np.size(frame, 1)\n",
    "height = np.size(frame, 0)\n",
    "\n",
    "def corner(filename) : \n",
    " im= filename\n",
    "\n",
    " gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    " corners = cv2.goodFeaturesToTrack(gray,25,0.01,10)\n",
    " corners = np.int0(corners)\n",
    "\n",
    " for i in corners:\n",
    "    x,y = i.ravel()\n",
    "    cv2.circle(img,(x,y),3,(0,0,255),-1)\n",
    " return im\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('output.avi',fourcc, 20.0, (640,480))\n",
    "i=0\n",
    "while True:\n",
    "    ret, img = cap.read()\n",
    "    #gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    #blur = cv2.GaussianBlur(gray,(5,5),0)\n",
    "    #thresh = cv2.adaptiveThreshold(blur,255,1,1,11,2)\n",
    "    \n",
    "    x = width/2-100\n",
    "    y = height/2-100\n",
    "    text_color = (0,0,255)\n",
    "    if(i>=120 and i<=150):\n",
    "        cv2.putText(img, \"your_string\", (x,y), cv2.FONT_HERSHEY_PLAIN, 12, text_color, thickness=10)\n",
    "    cv2.imshow(\"input\",corner(img))\n",
    "    #cv2.imshow(\"thresholded\", imgray*thresh2)\n",
    "    out.write(img)\n",
    "\n",
    "    key = cv2.waitKey(10)\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "\n",
    "cv2.destroyAllWindows() \n",
    "cv2.VideoCapture(0).release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
