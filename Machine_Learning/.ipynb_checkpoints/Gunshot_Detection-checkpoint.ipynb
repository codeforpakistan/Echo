{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import featureExtraction\n",
    "import numpy as np\n",
    "import librosa\n",
    "import MFCC\n",
    "import cPickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "featureExtraction.write_to_csv(\"/home/omer/Downloads/humans/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print MFCC.extract_mfcc(\"/home/omer/Desktop/UrbanSound8K/UrbanSound8K/audio/fold1/7061-6-0-0.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "array=np.loadtxt(open(\"/home/omer/Desktop/Echo/Machine_Learning/Data_Gunshot.csv\", \"r\"), delimiter=\",\", skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(866, 61)\n"
     ]
    }
   ],
   "source": [
    "print array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(866, 61)\n",
      "(166, 60) (866,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "np.random.shuffle(array)\n",
    "print array.shape\n",
    "X_train=array[:,1:]\n",
    "\n",
    "    \n",
    "y_train=array[:,0]\n",
    "X_test=array[700:,1:]\n",
    "y_test=array[700:,0]\n",
    "#print y_test\n",
    "print X_test.shape,y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started\n",
      "SVC(C=40, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma=0.0002, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "trained\n"
     ]
    }
   ],
   "source": [
    "print \"started\"\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import svm\n",
    "\n",
    "\n",
    "parameters = {'kernel':['rbf'], 'C':[ 10,40,60],'gamma':[0.001,0.007,0.0002,0.0003,0.0009]}\n",
    "svr = svm.SVC()\n",
    "\n",
    "clf =GridSearchCV(svr, parameters)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print clf.best_estimator_\n",
    "\n",
    "print \"trained\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set is :  100.0 %\n"
     ]
    }
   ],
   "source": [
    "print \"Accuracy on test set is : \",round(clf.score(X_test,y_test),2)*100 ,\"%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# save the classifier\n",
    "with open('my_dumped_classifierr.pkl', 'wb') as fid:\n",
    "    cPickle.dump(clf, fid)    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn_porter import Porter\n",
    "porter = Porter(clf, language='java')\n",
    "output = porter.export()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'y,sr=librosa.load(\"/home/omer/Downloads/videoplayback.wav\")\\nlibrosa.display.waveplot(y,sr)\\nmfcc=librosa.feature.mfcc(y=y,sr=sr,n_mfcc=60).T\\nmfcc=mfcc\\ni=0\\nj=0\\nprint mfcc.shape\\n#print clf.predict(np.mean(mfcc,0).reshape(1,60))\\nwhile (i<=mfcc.shape[0]):\\n    if(i<=4*42):\\n        j=0\\n        i+=42\\n        continue\\n     \\n    current=np.mean(mfcc[j:i,:],0 ).reshape(1,-1)\\n    print j,\"   \",i \\n    \\n    found=False\\n     \\n    #print clf.predict(current)\\n    if 1== clf.predict(current):\\n        found=True\\n    \\n    i+=42\\n    \\n    j+=42\\n\\n    if(found):\\n        print \"Benazir_Assasinaiton.wav :         GUNSHOT Detected\"\\n     \\n\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "with open('/home/omer/Desktop/Echo/Machine_Learning/my_dumped_classifierr.pkl', 'rb') as fid:\n",
    "    clf = cPickle.load(fid)\n",
    "\"\"\"y,sr=librosa.load(\"/home/omer/Downloads/videoplayback.wav\")\n",
    "librosa.display.waveplot(y,sr)\n",
    "mfcc=librosa.feature.mfcc(y=y,sr=sr,n_mfcc=60).T\n",
    "mfcc=mfcc\n",
    "i=0\n",
    "j=0\n",
    "print mfcc.shape\n",
    "#print clf.predict(np.mean(mfcc,0).reshape(1,60))\n",
    "while (i<=mfcc.shape[0]):\n",
    "    if(i<=4*42):\n",
    "        j=0\n",
    "        i+=42\n",
    "        continue\n",
    "     \n",
    "    current=np.mean(mfcc[j:i,:],0 ).reshape(1,-1)\n",
    "    print j,\"   \",i \n",
    "    \n",
    "    found=False\n",
    "     \n",
    "    #print clf.predict(current)\n",
    "    if 1== clf.predict(current):\n",
    "        found=True\n",
    "    \n",
    "    i+=42\n",
    "    \n",
    "    j+=42\n",
    "\n",
    "    if(found):\n",
    "        print \"Benazir_Assasinaiton.wav :         GUNSHOT Detected\"\n",
    "     \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<pydub.audio_segment.AudioSegment object at 0x7ff53b51c190>, <pydub.audio_segment.AudioSegment object at 0x7ff53b51c150>, <pydub.audio_segment.AudioSegment object at 0x7ff53b51c090>, <pydub.audio_segment.AudioSegment object at 0x7ff53b51c110>, <pydub.audio_segment.AudioSegment object at 0x7ff53b51c0d0>, <pydub.audio_segment.AudioSegment object at 0x7ff53b51c1d0>, <pydub.audio_segment.AudioSegment object at 0x7ff53b51c210>, <pydub.audio_segment.AudioSegment object at 0x7ff53b51c250>, <pydub.audio_segment.AudioSegment object at 0x7ff53b51c290>, <pydub.audio_segment.AudioSegment object at 0x7ff53b51c2d0>, <pydub.audio_segment.AudioSegment object at 0x7ff53b51c310>, <pydub.audio_segment.AudioSegment object at 0x7ff53b51c350>, <pydub.audio_segment.AudioSegment object at 0x7ff53b51c390>, <pydub.audio_segment.AudioSegment object at 0x7ff53b51c3d0>, <pydub.audio_segment.AudioSegment object at 0x7ff53b51c410>]\n",
      "exporting chunk0.wav\n",
      "[ 1.]\n",
      "exporting chunk1.wav\n",
      "[ 1.]\n",
      "exporting chunk2.wav\n",
      "[ 0.]\n",
      "exporting chunk3.wav\n",
      "[ 1.]\n",
      "exporting chunk4.wav\n",
      "[ 0.]\n",
      "exporting chunk5.wav\n",
      "[ 0.]\n",
      "exporting chunk6.wav\n",
      "[ 0.]\n",
      "exporting chunk7.wav\n",
      "[ 0.]\n",
      "exporting chunk8.wav\n",
      "[ 0.]\n",
      "exporting chunk9.wav\n",
      "[ 1.]\n",
      "exporting chunk10.wav\n",
      "[ 1.]\n",
      "exporting chunk11.wav\n",
      "[ 1.]\n",
      "exporting chunk12.wav\n",
      "[ 0.]\n",
      "exporting chunk13.wav\n",
      "[ 1.]\n",
      "exporting chunk14.wav\n",
      "[ 0.]\n"
     ]
    }
   ],
   "source": [
    "from pydub import AudioSegment\n",
    "from pydub.utils import make_chunks\n",
    "import os,librosa\n",
    "os.chdir(\"/home/omer/Desktop/\")\n",
    "myaudio = AudioSegment.from_file(\"Echo/Machine_Learning/Benazir Bhutto Assassination Video (Very High Quality).wav\" , \"wav\") \n",
    "chunk_length_ms = 5000 # pydub calculates in millisec\n",
    "chunks = make_chunks(myaudio, chunk_length_ms) #Make chunks of one sec\n",
    "print chunks\n",
    "#Export all of the individual chunks as wav files\n",
    " \n",
    "for i, chunk in enumerate(chunks):\n",
    "    \n",
    "    chunk_name = \"chunk\"+str(i)+\".wav\"\n",
    "    print \"exporting\", chunk_name\n",
    "    chunk.export(chunk_name, format=\"wav\")\n",
    "    y,sr=librosa.load(chunk_name)\n",
    "    \n",
    "    mfcc=librosa.feature.mfcc(y=y,sr=sr,n_mfcc=60).T\n",
    "    print clf.predict(np.mean(mfcc,0).reshape(1,-1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
